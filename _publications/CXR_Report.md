---
title: "Representative image feature extraction via contrastive learning pretraining for chest x-ray report generation"
collection: publications
permalink: 
excerpt: ''
date: 2022/09
venue: 
slidesurl: 
paperurl: 'https://arxiv.org/abs/2209.01604'
citation: 'Chen, Yu-Jen, et al. "Representative image feature extraction via contrastive learning pretraining for chest x-ray report generation." arXiv preprint arXiv:2209.01604 (2022).'
---

![clnlp](https://user-images.githubusercontent.com/43490777/203788648-9d0aad88-07bd-4920-9346-988b8968227c.png)

Medical report generation is a challenging task since it is time-consuming and requires expertise from experienced radiologists. The goal of medical report generation is to accurately capture and describe the image findings. Previous works pretrain their visual encoding neural networks with large datasets in different domains, which cannot learn general visual representation in the specific medical domain. In this work, we propose a medical report generation framework that uses a contrastive learning approach to pretrain the visual encoder and requires no additional meta information. In addition, we adopt lung segmentation as an augmentation method in the contrastive learning framework. This segmentation guides the network to focus on encoding the visual feature within the lung region. Experimental results show that the proposed framework improves the performance and the quality of the generated medical reports both quantitatively and qualitatively.
